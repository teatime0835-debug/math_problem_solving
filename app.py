import streamlit as st
from openai import OpenAI
from PIL import Image
import base64
import os
import json

# ===============================
# Streamlit ê¸°ë³¸ ì„¤ì •
# ===============================
st.set_page_config(
    page_title="ì¤‘í•™ìƒ ìˆ˜í•™ AI íŠœí„°",
    page_icon="ğŸ“˜",
    layout="centered"
)

st.title("ğŸ“˜ ì¤‘í•™ìƒ ìˆ˜í•™ AI íŠœí„°")
st.info(
    "ğŸ“Œ ì´ ì„œë¹„ìŠ¤ëŠ” **êµìœ¡ ëª©ì ì˜ AI ì‹œì—°**ì…ë‹ˆë‹¤.\n\n"
    "- ë¬¸ì œ ë¶„ì„ ë° ìœ ì‚¬ ë¬¸ì œëŠ” í•™ìŠµìš©ì…ë‹ˆë‹¤.\n"
    "- ì •ë‹µê³¼ í’€ì´ëŠ” ë²„íŠ¼ì„ ëˆŒëŸ¬ í™•ì¸í•˜ì„¸ìš”."
)

# ===============================
# OpenAI API
# ===============================
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=API_KEY)

# ===============================
# ì¤‘í•™êµ 1Â·2Â·3í•™ë…„ ë‹¨ì› ì²´ê³„ (ìµœì¢… í™•ì •ë³¸)
# ===============================
CURRICULUM = {
    "1í•™ë…„": {
        "4. ì¢Œí‘œí‰ë©´ê³¼ ê·¸ë˜í”„": [
            "4.1 ìˆœì„œìŒê³¼ ì¢Œí‘œ",
            "4.2 ê·¸ë˜í”„ì˜ ëœ»ê³¼ í‘œí˜„",
            "4.3 ì •ë¹„ë¡€ì™€ ê·¸ ê·¸ë˜í”„",
            "4.4 ë°˜ë¹„ë¡€ì™€ ê·¸ ê·¸ë˜í”„",
        ],
        "7. ì…ì²´ë„í˜•ì˜ ì„±ì§ˆ": [
            "7.1 ë‹¤ë©´ì²´",
            "7.2 íšŒì „ì²´",
            "7.3 ê¸°ë‘¥ê³¼ ë¿”ì˜ ê²‰ë„“ì´",
            "7.4 ê¸°ë‘¥ê³¼ ë¿”ì˜ ë¶€í”¼",
            "7.5 êµ¬ì˜ ê²‰ë„“ì´ì™€ ë¶€í”¼",
        ],
    },
    "2í•™ë…„": {
        "4. ì¼ì°¨í•¨ìˆ˜ì™€ ê·¸ë˜í”„": [
            "4.1 í•¨ìˆ˜ì™€ í•¨ìˆ«ê°’",
            "4.2 ì¼ì°¨í•¨ìˆ˜ì˜ ëœ»ê³¼ ê·¸ë˜í”„",
            "4.3 ì ˆí¸ê³¼ ê¸°ìš¸ê¸°",
            "4.4 ê·¸ë˜í”„ì˜ ì„±ì§ˆ",
            "4.5 ì¼ì°¨í•¨ìˆ˜ì‹ êµ¬í•˜ê¸°",
            "4.6 ì¼ì°¨í•¨ìˆ˜ì™€ ì¼ì°¨ë°©ì •ì‹",
            "4.7 ë‘ ì¼ì°¨í•¨ìˆ˜ì™€ ì—°ë¦½ì¼ì°¨ë°©ì •ì‹",
        ],
    },
    "3í•™ë…„": {
        "7. í†µê³„": [
            "7.1 ëŒ€í‘¯ê°’",
            "7.2 ë¶„ì‚°ê³¼ í‘œì¤€í¸ì°¨",
            "7.3 ì‚°ì ë„ì™€ ìƒê´€ê´€ê³„",
        ],
    },
}

# ===============================
# ì´ë¯¸ì§€ ì—…ë¡œë“œ
# ===============================
uploaded_file = st.file_uploader("ğŸ“· ë¬¸ì œ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ì—…ë¡œë“œëœ ë¬¸ì œ", use_container_width=True)

    base64_img = base64.b64encode(uploaded_file.getvalue()).decode()

    # ===============================
    # 1ï¸âƒ£ ë¬¸ì œ ë¶„ì„
    # ===============================
    if st.button("ğŸ” ë¬¸ì œ ë¶„ì„"):
        with st.spinner("ë¬¸ì œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            analysis_prompt = """
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì¤‘í•™êµ ìˆ˜í•™ êµì‚¬ì•¼.

ì•„ë˜ ì¤‘í•™êµ ìˆ˜í•™ ë‹¨ì› ì²´ê³„ ì•ˆì—ì„œë§Œ ì„ íƒí•´ì„œ
ì‚¬ì§„ ì† ë¬¸ì œë¥¼ ê°€ì¥ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´.

ğŸ“Œ íŒë‹¨ ê¸°ì¤€
1. ë¬¸ì œ í•´ê²°ì— ë°˜ë“œì‹œ í•„ìš”í•œ í•µì‹¬ ê°œë…
2. ëŒ€í‘œì ì¸ ë‹¨ì› ê³ ìœ  ë¬¸ì œ ìœ í˜•
3. ì• ë§¤í•˜ë©´ ê°€ì¥ ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ëœ ê°œë… ê¸°ì¤€

ğŸ“Œ ì¶œë ¥ í˜•ì‹ (JSONë§Œ!)
{
  "í•™ë…„": "",
  "ëŒ€ë‹¨ì›": "",
  "ì†Œë‹¨ì›": "",
  "ë¬¸ì œìœ í˜•": ""
}
"""

            res = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": analysis_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_img}"}}
                    ]
                }]
            )

            try:
                st.session_state.analysis = json.loads(
                    res.choices[0].message.content.strip()
                )
            except:
                st.error("âŒ ë¬¸ì œ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                st.stop()

# ===============================
# ë¶„ì„ ê²°ê³¼ ìˆ˜ì • UI
# ===============================
if "analysis" in st.session_state:
    st.markdown("## ğŸ› ï¸ ë¬¸ì œ ë¶„ì„ ê²°ê³¼")

    grade = st.selectbox(
        "í•™ë…„",
        CURRICULUM.keys(),
        index=list(CURRICULUM.keys()).index(
            st.session_state.analysis.get("í•™ë…„", "1í•™ë…„")
        )
    )

    big_unit = st.selectbox(
        "ëŒ€ë‹¨ì›",
        CURRICULUM[grade].keys()
    )

    small_unit = st.selectbox(
        "ì†Œë‹¨ì›",
        CURRICULUM[grade][big_unit]
    )

    problem_type = st.text_input(
        "ë¬¸ì œ ìœ í˜•",
        st.session_state.analysis.get("ë¬¸ì œìœ í˜•", "")
    )

    # ===============================
    # 2ï¸âƒ£ ìœ ì‚¬ ë¬¸ì œ ìƒì„±
    # ===============================
    if st.button("ğŸ§© ìœ ì‚¬ ë¬¸ì œ ìƒì„±"):
        with st.spinner("ìœ ì‚¬ ë¬¸ì œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            gen_prompt = f"""
ë„ˆëŠ” ì¤‘í•™êµ ìˆ˜í•™ ë¬¸ì œ ì¶œì œ ì „ë¬¸ê°€ì•¼.

ğŸ“Œ ì¡°ê±´
- í•™ë…„: {grade}
- ëŒ€ë‹¨ì›: {big_unit}
- ì†Œë‹¨ì›: {small_unit}
- ë¬¸ì œ ìœ í˜•: {problem_type}

ğŸ“Œ ì¶œì œ ê·œì¹™
- ì›ë˜ ë¬¸ì œì™€ ê±°ì˜ ë™ì¼í•œ ìœ í˜•
- ìˆ«ìë‚˜ ì¡°ê±´ë§Œ ì•½ê°„ ë³€ê²½
- ë‹¨ì› ì´íƒˆ ì ˆëŒ€ ê¸ˆì§€

ğŸ“Œ ì¶œë ¥ í˜•ì‹
1. ë„¤ëª¨ ë°•ìŠ¤ ì•ˆì— ë¬¸ì œ ì œì‹œ
2. ë¬¸ì œ ì•„ë˜ì— ë¬¸ì œ ìœ í˜• 1~2ê°œë§Œ ê°„ë‹¨íˆ í‘œì‹œ
3. ì •ë‹µê³¼ í’€ì´ëŠ” ì“°ì§€ ë§ ê²ƒ
"""

            out = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": gen_prompt}]
            )

            st.session_state.similar_problem = out.choices[0].message.content
            st.session_state.show_answer = False
            st.session_state.show_solution = False

# ===============================
# ìœ ì‚¬ ë¬¸ì œ ì¶œë ¥
# ===============================
if "similar_problem" in st.session_state:
    st.markdown("## ğŸ§© ìœ ì‚¬ ë¬¸ì œ")
    st.markdown(st.session_state.similar_problem)

    col1, col2 = st.columns(2)

    with col1:
        if st.button("âœ… ì •ë‹µ ë³´ê¸°"):
            st.session_state.show_answer = True

    with col2:
        if st.button("ğŸ“˜ í’€ì´ ë³´ê¸°"):
            st.session_state.show_solution = True

# ===============================
# ì •ë‹µ / í’€ì´
# ===============================
if st.session_state.get("show_answer") or st.session_state.get("show_solution"):
    solve_prompt = f"""
ë„ˆëŠ” ì¤‘í•™êµ ìˆ˜í•™ êµì‚¬ì•¼.

ì•„ë˜ [ìœ ì‚¬ ë¬¸ì œ]ì— ëŒ€í•´
- ì •ë‹µ
- í’€ì´ ê³¼ì •

ì„ ì‘ì„±í•´.

ğŸ“Œ ê·œì¹™
- ìˆ«ìÃ—ìˆ«ì â†’ ë°˜ë“œì‹œ Ã— ì‚¬ìš©
- ìˆ«ìÃ—ë¬¸ì, ë¬¸ìÃ—ë¬¸ì â†’ ê³±ì…ˆê¸°í˜¸ ìƒëµ
- ë‹¨ê³„ë³„ë¡œ ê°„ê²°í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…

[ìœ ì‚¬ ë¬¸ì œ]
{st.session_state.similar_problem}
"""

    sol = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": solve_prompt}]
    )

    if st.session_state.get("show_answer"):
        st.markdown("### âœ… ì •ë‹µ")
        st.markdown(sol.choices[0].message.content.split("í’€ì´")[0])

    if st.session_state.get("show_solution"):
        st.markdown("### ğŸ“˜ í’€ì´")
        st.markdown(sol.choices[0].message.content)

# ===============================
# Footer
# ===============================
st.markdown("---")
st.caption("Â© 2026 ì¸ê³µì§€ëŠ¥ìœµí•©êµìœ¡ í”„ë¡œì íŠ¸ | ì¤‘í•™ìƒ ìˆ˜í•™ AI íŠœí„° (êµìœ¡ìš©)")
